---
title: "Project 1"
author: "Chris Cavan, Marshall Ndhlovu, Noah Maddio, Nathan Gottwals"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Processing

```{r Libraries, warning=FALSE,message=FALSE,error=FALSE, results='hide'}
rm(list = ls())
# libraries 
library(tidyverse)
library(lubridate)
library(dplyr)
library(ggcorrplot)
library(gridExtra)
library(tidyr)
library(ggplot2)
library(RColorBrewer)
library(reticulate)
library(fuzzywuzzyR)
library(plotly)
library(GGally)
library(imputeTS)
library(randomForest)
library(TSstudio)
library(randomForest) #to fit random forest
library(pROC) # for ROC curves
library(rlist)

# In reticulate's python environment install (from the r terminal):
# numpy
# polyfuzz
# seaborn
# pandas
# matplotlib

# python modules 
DIFFLIB <- reticulate::import("difflib")
POLYFUZZ <- reticulate::import("polyfuzz")


```
All r code and rmarkdown will be in the root directory with and all sensory data are to be in the directory Data/Wind Turbine Data Batch 2/ and extracted into their respective sub directories as stated:\

**Work order**

+ Data/Wind Turbine Data Batch 2/Work Order
  
**Active Power**

+ Data/Wind Turbine Data Batch 2/Active Power
  
**Gearbox HS Bearing Temperature**
  
+ Data/Wind Turbine Data Batch 2/Gearbox HS Bearing
  
**Gearbox IMS Bearing 1**
  
+ Data/Wind Turbine Data Batch 2/Gearbox IMS Bearing 1
  
**Gearbox IMS Bearing 2**
  
+ Data/Wind Turbine Data Batch 2/Gearbox IMS Bearing 2
  
**Gearbox Oil**

+ Gearbox Oil
  
**Generator RPM**

+ Data/Wind Turbine Data Batch 2/Gearbox RPM
  
**Hydraulic Pressure**

+ Data/Wind Turbine Data Batch 2/Hydraulic Pressure
  
**Windspeed**

+ Data/Wind Turbine Data Batch 2/Windspeed

#Reading in the data and cleaning
The data for the supplied sensor metrics are read in and the dates and time are converted to a usable date format. The data of the metrics are
then aggregated by the average in 60 minutes intervals. The data frames are then joined by the Turbine and with the date and time of the averaged metric.


```{r data_processing, eval=FALSE}
#### ***Rmarkdown: Will not run when kniting unless you remove eval=FALSE ^


#####workorder------------
# gets a list of all of the csv files in the directory
wo_files = list.files("Data/Wind Turbine Data Batch 2/Work Order", pattern="*.csv")
# declaring a list and then adding files names of csvs to that list that have a file size larger than 1
wo_list = list()
for (i in 1:length(wo_files)) {
  if (file.size(paste0("Data/Wind Turbine Data Batch 2/Work Order/", wo_files[i])) >1){
    wo_list = c(wo_list, wo_files[i])
  }
}
# reading in the first non empty csv from the list to a dataframe
wo = read.csv(paste0("Data/Wind Turbine Data Batch 2/Work Order/", wo_list[1]), header = TRUE)
# adding the rest of the csvs from the list
# There is only one. There rest of the sensory data has multiple so there is a loop for that

# work order exploration and data cleaning
# cause_code all null
#table(wo$cause_code)
# start date is character
#convert start and finish columns to date objects
wo$wo_start_date = ymd_hms(wo$wo_start_date)
# end date is also character
#convert start and finish columns to date objects
wo$wo_finish_date = ymd_hms(wo$wo_finish_date)
#table(wo$cause_code)

# This first converts the string "null" into a NA value. Then by grouping of OrderNo, fills in NA's with existing values of component_type, within a OrderNo if they exist. Then distinct() is ran to keep only unique rows. This allows us to keep unique work order numbers with component types when it is available. 
workorder = wo %>% 
    mutate(component_type = case_when(component_type == "null" ~ NA_character_,
                               TRUE ~ component_type)) %>% 
    group_by(OrderNo) %>% 
    fill(component_type, .direction = 'up') %>% 
    fill(component_type, .direction = 'down') %>% distinct(OrderNo, .keep_all = TRUE)
# compared to this which just keeps distinct OrderNo regardless of other variables, causing us to lose most of the component_type 
# test = distinct(wo, OrderNo, .keep_all = TRUE)

str(workorder)

#### fault code---------------- 
fault_files = list.files("Data/Wind Turbine Data Batch 2/Fault Status Codes", pattern="*.csv")
fault_list = list()
for (i in 1:length(fault_files)) {
  if (file.size(paste0("Data/Wind Turbine Data Batch 2/Fault Status Codes/", fault_files[i])) >1){
    fault_list = c(fault_list, fault_files[i])
  }
}
fault = read.csv(paste0("Data/Wind Turbine Data Batch 2/Fault Status Codes/", fault_list[1]), header = FALSE)
for (i in 2:length(fault_list)){
  new = read.csv(paste0("Data/Wind Turbine Data Batch 2/Fault Status Codes/", fault_list[i]), header = FALSE)
  fault = rbind(fault, new)
}
#renaming column headers
names(fault) <- c("location_id", "DateTime", "Date", "FaultCode", "StatusCode", "Description", "Type")

fault$DateTime <- ymd_hms(fault$DateTime)
fault$Date <- ymd(fault$Date)

#------------------------------Remove duplicates of fault code pinging for consecutive intervals---------------####
# order fault data by turbine, date, and fault code
fault <- fault[order(fault$location_id, fault$Date, fault$FaultCode),]
# create new time difference variable to help remove duplicates
fault$Time_Diff = NA


# The first occurrence of a fault will have a 0 for time difference
for(i in 2:length(fault$Date)){
  # take time difference of two lines if they are the same fault code and same turbine id
  if (fault$location_id[i] == fault$location_id[i-1] && fault$FaultCode[i] == fault$FaultCode[i-1]){
    fault$Time_Diff[i] = as.numeric(difftime(fault$Date[i], fault$Date[i-1], 'days'))
  }
  # new faults or turbines (different from previous row) will start again at 0
  else fault$Time_Diff[i] = 0 # 0 does not matter because it will not be used for removal
}

# set first line time difference to 0
fault$Time_Diff[1] = 0

# remove duplicates on the same day (only keep first occurrence of certain fault on a day)
fault <- fault[!duplicated(fault[c("location_id", "Date", "FaultCode")]),]

# remove duplicates of the same fault rolling into the next day and every consecutive day
# example: on the first line where the same fault rolls over into the next day, the time difference from the previous
#   line will be 1. Every other occurrence on the same day was already removed, but the next day where it rolled over
#   will also have a 1. Thus, remove all 1's so the only thing that stands was the first occurrence in the entire series
#   of intervals.
fault <- fault %>% filter(Time_Diff != 1)


#Adding a variable round_date to round times to nearest 60 minutes intervals
fault$round_date <- lubridate::round_date(fault$DateTime, "60 minutes")
## keeping only one observation of each fault code of each turbine's 60 minutes interval
fault <- fault %>% distinct(location_id, round_date,FaultCode, .keep_all = TRUE)
# removing unused columns
fault = subset(fault, select=-c(Time_Diff,DateTime,Date,StatusCode))


#### Gearbox HS Bearing Temperature---------------- 
bearing_files = list.files("Data/Wind Turbine Data Batch 2/Gearbox HS Bearing", pattern="*.csv")
bearing_list = list()
for (i in 1:length(bearing_files)) {
  if (file.size(paste0("Data/Wind Turbine Data Batch 2/Gearbox HS Bearing/", bearing_files[i])) >1){
    bearing_list = c(bearing_list, bearing_files[i])
  }
}
bearing = read.csv(paste0("Data/Wind Turbine Data Batch 2/Gearbox HS Bearing/", bearing_list[1]), header = FALSE)
for (i in 2:length(bearing_list)){
  new = read.csv(paste0("Data/Wind Turbine Data Batch 2/Gearbox HS Bearing/", bearing_list[i]), header = FALSE)
  bearing = rbind(bearing, new)
}
#convert Datetime from char to date
bearing$V2 <- ymd_hms(bearing$V2)
#renaming column headers
names(bearing) <- c("location_id", "DateTime", "Date", "Temperature", "Bearing HS")
# sorting data by turbine, then the DateTime.
bearing <- bearing %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 60 minutes intervals
bearing$round_date <- lubridate::round_date(bearing$DateTime, "60 minutes")
#adding mean, max, min and sd of the 60 minutes intervals and dropping columns
bearing <-bearing %>% group_by(location_id, round_date) %>% summarise(mean_bearing = mean(Temperature), max_bearing = max(Temperature), min_bearing = min(Temperature), sd_bearing = sd(Temperature), .groups = 'drop') %>% as.data.frame



#### Gearbox IMS Bearing  1 Temperature---------------- 
ims_files = list.files("Data/Wind Turbine Data Batch 2/Gearbox IMS Bearing 1", pattern="*.csv")
ims_list = list()
for (i in 1:length(ims_files)) {
  if (file.size(paste0("Data/Wind Turbine Data Batch 2/Gearbox IMS Bearing 1/", ims_files[i])) >1){
    ims_list = c(ims_list, ims_files[i])
  }
}
ims = read.csv(paste0("Data/Wind Turbine Data Batch 2/Gearbox IMS Bearing 1/", ims_list[1]), header = FALSE)
for (i in 2:length(ims_list)){
  new = read.csv(paste0("Data/Wind Turbine Data Batch 2/Gearbox IMS Bearing 1/", ims_list[i]), header = FALSE)
  ims = rbind(ims, new)
}
#convert Datetime from char to date
ims$V2 <- ymd_hms(ims$V2)
#renaming column headers
names(ims) <- c("location_id", "DateTime", "Date", "Temperature", "ims")
# sorting data by turbine, then the DateTime.
ims <- ims %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 60 minutes intervals
ims$round_date <- lubridate::round_date(ims$DateTime, "60 minutes")
#adding mean, max, min and sd ims bearing temp of the 60 minutes intervals and dropping columns
ims <-ims %>% group_by(location_id, round_date) %>% summarise(mean_ims = mean(Temperature), max_ims = max(Temperature), min_ims = min(Temperature), sd_ims = sd(Temperature), .groups = 'drop') %>% as.data.frame


#### Gearbox IMS Bearing  2 Temperature---------------- 
ims_files2 = list.files("Data/Wind Turbine Data Batch 2/Gearbox IMS Bearing 2", pattern="*.csv")
ims_list2 = list()
for (i in 1:length(ims_files2)) {
  if (file.size(paste0("Data/Wind Turbine Data Batch 2/Gearbox IMS Bearing 2/", ims_files2[i])) >1){
    ims_list2 = c(ims_list2, ims_files2[i])
  }
}
ims2 = read.csv(paste0("Data/Wind Turbine Data Batch 2/Gearbox IMS Bearing 2/", ims_list2[1]), header = FALSE)
for (i in 2:length(ims_list2)){
  new = read.csv(paste0("Data/Wind Turbine Data Batch 2/Gearbox IMS Bearing 2/", ims_list2[i]), header = FALSE)
  ims2 = rbind(ims2, new)
}
#convert Datetime from char to date
ims2$V2 <- ymd_hms(ims2$V2)
#renaming column headers
names(ims2) <- c("location_id", "DateTime", "Date", "Temperature", "ims_2")
# sorting data by turbine, then the DateTime.
ims2 <- ims2 %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 60 minutes intervals
ims2$round_date <- lubridate::round_date(ims2$DateTime, "60 minutes")
#adding mean, max, min and sd ims2 bearing temp of the 60 minutes intervals and dropping columns
ims2 <-ims2 %>% group_by(location_id, round_date) %>% summarise(mean_ims2 = mean(Temperature), max_ims2 = max(Temperature), min_ims2 = min(Temperature), sd_ims2 = sd(Temperature), .groups = 'drop') %>% as.data.frame


#### Gearbox Oil---------------- 
oil_files = list.files("Data/Wind Turbine Data Batch 2/Gearbox Oil", pattern="*.csv")
oil_list = list()
for (i in 1:length(oil_files)) {
  if (file.size(paste0("Data/Wind Turbine Data Batch 2/Gearbox Oil/", oil_files[i])) >1){
    oil_list = c(oil_list, oil_files[i])
  }
}
oil = read.csv(paste0("Data/Wind Turbine Data Batch 2/Gearbox Oil/", oil_list[1]), header = FALSE)
for (i in 2:length(oil_list)){
  new = read.csv(paste0("Data/Wind Turbine Data Batch 2/Gearbox Oil/", oil_list[i]), header = FALSE)
  oil = rbind(oil, new)
}
#convert Datetime from char to date
oil$V2 <- ymd_hms(oil$V2)
#renaming column headers
names(oil) <- c("location_id", "DateTime", "Date", "Temperature", "oil")
# sorting data by turbine, then the DateTime.
oil <- oil %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 60 minutes intervals
oil$round_date <- lubridate::round_date(oil$DateTime, "60 minutes")
#adding mean, max, min and sd oil temp of the 60 minutes intervals and dropping columns
oil <-oil %>% group_by(location_id, round_date) %>% summarise(mean_oil = mean(Temperature), max_oil = max(Temperature), min_oil = min(Temperature), sd_oil = sd(Temperature), .groups = 'drop') %>% as.data.frame


#### Generator RPM---------------- 
rpm_files = list.files("Data/Wind Turbine Data Batch 2/Generator RPM", pattern="*.csv")
rpm_list = list()
for (i in 1:length(rpm_files)) {
  if (file.size(paste0("Data/Wind Turbine Data Batch 2/Generator RPM/", rpm_files[i])) >1){
    rpm_list = c(rpm_list, rpm_files[i])
  }
}
rpm = read.csv(paste0("Data/Wind Turbine Data Batch 2/Generator RPM/", rpm_list[1]), header = FALSE)
for (i in 2:length(rpm_list)){
  new = read.csv(paste0("Data/Wind Turbine Data Batch 2/Generator RPM/", rpm_list[i]), header = FALSE)
  rpm = rbind(rpm, new)
}
#convert Datetime from char to date
rpm$V2 <- ymd_hms(rpm$V2)
#renaming column headers
names(rpm) <- c("location_id", "DateTime", "Date", "RPM", "Generator rpm")
# sorting data by turbine, then the DateTime.
rpm <- rpm %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 60 minutes intervals
rpm$round_date <- lubridate::round_date(rpm$DateTime, "60 minutes")
# adding mean, max, min and sd rpm of the 60 minutes intervals and dropping columns
# Removing keeping only one observation of the mean for each turbine's 60 minutes interval
rpm <-rpm %>% group_by(location_id, round_date) %>% summarise(mean_rpm = mean(RPM), max_rpm = max(RPM), min_rpm = min(RPM), sd_rpm = sd(RPM), .groups = 'drop') %>% as.data.frame



#### Hydraulic Pressure---------------- 
hydraulic_files = list.files("Data/Wind Turbine Data Batch 2/Hydraulic Pressure", pattern="*.csv")
hydraulic_list = list()
for (i in 1:length(hydraulic_files)) {
  if (file.size(paste0("Data/Wind Turbine Data Batch 2/Hydraulic Pressure/", hydraulic_files[i])) >1){
    hydraulic_list = c(hydraulic_list, hydraulic_files[i])
  }
}
hydraulic = read.csv(paste0("Data/Wind Turbine Data Batch 2/Hydraulic Pressure/", hydraulic_list[1]), header = FALSE)
for (i in 2:length(hydraulic_list)){
  new = read.csv(paste0("Data/Wind Turbine Data Batch 2/Hydraulic Pressure/", hydraulic_list[i]), header = FALSE)
  hydraulic = rbind(hydraulic, new)
}
#convert Datetime from char to date
hydraulic$V2 <- ymd_hms(hydraulic$V2)
#renaming column headers
names(hydraulic) <- c("location_id", "DateTime", "Date", "Pressure", "Hydraulic Pressure")
# sorting data by turbine, then the DateTime.
hydraulic <- hydraulic %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 60 minutes intervals
hydraulic$round_date <- lubridate::round_date(hydraulic$DateTime, "60 minutes")
#adding mean, max, min and sd of hydraulic pressure of the 60 minutes intervals and dropping columns
hydraulic <-hydraulic %>% group_by(location_id, round_date) %>% summarise(mean_hydraulic = mean(Pressure), max_hydraulic = max(Pressure), min_hydraulic = min(Pressure), sd_hydraulic = sd(Pressure), .groups = 'drop') %>% as.data.frame


#### active power-------------- 
active_files = list.files("Data/Wind Turbine Data Batch 2/Active Power", pattern="*.csv")
active_list = list()
for (i in 1:length(active_files)) {
  if (file.size(paste0("Data/Wind Turbine Data Batch 2/Active Power/", active_files[i])) >1){
    active_list = c(active_list, active_files[i])
  }
}
active = read.csv(paste0("Data/Wind Turbine Data Batch 2/Active Power/", active_list[1]), header = FALSE)
for (i in 2:length(active_list)){
  new = read.csv(paste0("Data/Wind Turbine Data Batch 2/Active Power/", active_list[i]), header = FALSE)
  active = rbind(active, new)
}
#convert Datetime from char to date
active$V2 <- ymd_hms(active$V2)
#renaming column headers
names(active) <- c("location_id", "DateTime", "Date", "power", "Active power")
# sorting data by turbine, then the DateTime.
active <- active %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 60 minutes intervals
active$round_date <- lubridate::round_date(active$DateTime, "60 minutes")
# adding mean, max, min and sd active power of the 60 minutes intervals and dropping columns
active <-active %>% group_by(location_id, round_date) %>% summarise(mean_active = mean(power), max_active = max(power), min_active = min(power), sd_active = sd(power), .groups = 'drop')



#### Ambient Temperature-------------- 
ambient_files = list.files("Data/Wind Turbine Data Batch 2/Ambient Temperature", pattern="*.csv")
ambient_list = list()
for (i in 1:length(ambient_files)) {
  if (file.size(paste0("Data/Wind Turbine Data Batch 2/Ambient Temperature/", ambient_files[i])) >1){
    ambient_list = c(ambient_list, ambient_files[i])
  }
}
ambient = read.csv(paste0("Data/Wind Turbine Data Batch 2/Ambient Temperature/", ambient_list[1]), header = FALSE)
for (i in 2:length(ambient_list)){
  new = read.csv(paste0("Data/Wind Turbine Data Batch 2/Ambient Temperature/", ambient_list[i]), header = FALSE)
  ambient = rbind(ambient, new)
}
#convert Datetime from char to date
ambient$V2 <- ymd_hms(ambient$V2)
#renaming column headers
names(ambient) <- c("location_id", "DateTime", "Date", "ambient_temp", "Ambient Temperature")
# sorting data by turbine, then the DateTime.
ambient <- ambient %>% 
  arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 60 minutes intervals
ambient$round_date <- lubridate::round_date(ambient$DateTime, "60 minutes")
#adding mean, max, min and sd power of the 60 minutes intervals and dropping columns
ambient <-ambient %>% group_by(location_id, round_date) %>% summarise(mean_ambient = mean(ambient_temp), max_ambient = max(ambient_temp), min_ambient = min(ambient_temp), sd_ambient = sd(ambient_temp), .groups = 'drop') %>% as.data.frame

#### Wind Speed-------------- 
wind_files = list.files("Data/Wind Turbine Data Batch 2/Windspeed", pattern="*.csv")
wind_list = list()
for (i in 1:length(wind_files)) {
  if (file.size(paste0("Data/Wind Turbine Data Batch 2/Windspeed/", wind_files[i])) >1){
    wind_list = c(wind_list, wind_files[i])
  }
}
wind = read.csv(paste0("Data/Wind Turbine Data Batch 2/Windspeed/", wind_list[1]), header = FALSE)
for (i in 2:length(wind_list)){
  new = read.csv(paste0("Data/Wind Turbine Data Batch 2/Windspeed/", wind_list[i]), header = FALSE)
  wind = rbind(wind, new)
}
#convert Datetime from char to date
wind$V2 <- ymd_hms(wind$V2)
#renaming column headers
names(wind) <- c("location_id", "DateTime", "Date", "windspeed", "Wind Speed")
# sorting data by turbine, then the DateTime.
wind <- wind %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 60 minutes intervals
wind$round_date <- lubridate::round_date(wind$DateTime, "60 minutes")
#adding mean, max, min and sd power of the 60 minutes intervals and dropping columns
wind <-wind %>% group_by(location_id, round_date) %>% summarise(mean_windspeed = mean(windspeed), max_windspeed = max(windspeed), min_windspeed = min(windspeed), sd_windspeed = sd(windspeed), .groups = 'drop') %>% as.data.frame()

```

```{r, joining}

####Joining datasets------
fully_joined <- full_join(wind, bearing, by=c('location_id', 'round_date')) %>%
  full_join(., hydraulic, c('location_id', 'round_date')) %>%
  full_join(., rpm, c('location_id', 'round_date')) %>%
  full_join(., oil, c('location_id', 'round_date')) %>%
  full_join(., ims, c('location_id', 'round_date')) %>%
  full_join(., ims2, c('location_id', 'round_date')) %>%
  full_join(., active, c('location_id', 'round_date'))%>%
  full_join(., ambient, by=c('location_id', 'round_date'))

fully_joined <- left_join(fully_joined, fault, by=c('location_id', 'round_date'))


#Note Date should be the just the ymd the same as round_date's ymd_hms, but since during aggregation something like 23:57 would be rounded to 00:00am of the next day,
# but would have the previous date in Date and the next day's date in round_date. We will just fix that.
fully_joined$Date = fully_joined$round_date
fully_joined$Date = format(fully_joined$Date, "%Y-%m-%d")




#save spot copy of data 
path_out = 'Data/'
write.csv(fully_joined,paste(path_out,'final_data-v8.csv',sep = ''),row.names=FALSE)

# load save point
fully_joined <- read.csv("Data/final_data-v8.csv")
fully_joined$round_date <- ymd_hms(fully_joined$round_date)
fully_joined$Date <- ymd(fully_joined$Date)


```

### Lag varaibles
```{r, lag}

# Creating lag variables by 6 hours
db2 = fully_joined %>% group_by(location_id) %>% mutate(lag_mean_bearing = lag(mean_bearing,n=6),
                                          lag_max_bearing = lag(max_bearing,n=6),
                                          lag_min_bearing = lag(min_bearing,n=6),
                                          lag_sd_bearing = lag(sd_bearing,n=6),
                                          lag_mean_hydraulic = lag(mean_hydraulic,n=6),
                                          lag_max_hydraulic = lag(max_hydraulic,n=6),
                                          lag_min_hydraulic = lag(min_hydraulic,n=6),
                                          lag_sd_hydraulic = lag(sd_hydraulic,n=6),
                                          lag_mean_rpm = lag(mean_rpm,n=6),
                                          lag_max_rpm = lag(max_rpm,n=6),
                                          lag_min_rpm = lag(min_rpm,n=6),
                                          lag_sd_rpm = lag(sd_rpm,n=6),
                                          lag_mean_oil = lag(mean_oil,n=6),
                                          lag_max_oil = lag(max_oil,n=6),
                                          lag_min_oil = lag(min_oil,n=6),
                                          lag_sd_oil = lag(sd_oil,n=6),
                                          lag_mean_ims = lag(mean_ims,n=6),
                                          lag_max_ims = lag(max_ims,n=6),
                                          lag_min_ims = lag(min_ims,n=6),
                                          lag_sd_ims = lag(sd_ims,n=6),
                                          lag_mean_ims2 = lag(mean_ims2,n=6),
                                          lag_max_ims2 = lag(max_ims2,n=6),
                                          lag_min_ims2 = lag(min_ims2,n=6),
                                          lag_sd_ims2 = lag(sd_ims2,n=6),
                                          lag_mean_active = lag(mean_ims,n=6),
                                          lag_max_active = lag(max_active,n=6),
                                          lag_min_active = lag(min_active,n=6),
                                          lag_sd_active = lag(sd_active,n=6),
                                          lag_mean_ambient = lag(mean_ambient,n=6),
                                          lag_max_ambient = lag(max_ambient,n=6),
                                          lag_min_ambient = lag(min_ambient,n=6),
                                          lag_sd_ambient = lag(sd_ambient,n=6))
                                          

db2 = db2 %>% drop_na(lag_min_hydraulic)
db2 = subset(db2, select=-c(max_bearing,min_bearing,mean_bearing,sd_bearing,mean_hydraulic,max_hydraulic,min_hydraulic,sd_hydraulic,mean_rpm,max_rpm,min_rpm,sd_rpm,mean_oil,max_oil,min_oil,sd_oil,mean_ims,max_ims,min_ims,sd_ims,mean_ims2,max_ims2,min_ims2,sd_ims2,mean_ims,max_active,min_active,sd_active,mean_active,mean_ambient,max_ambient,min_ambient,sd_ambient))

```


```{r fault code Descriptions, eval=FALSE}
#### ***Rmarkdown: Will not run when knitting unless you remove eval=FALSE ^

unique(fully_joined$Description)
# If the Turbine stops and needs work, it's critical
# Warning is for what maybe a warning or something.
# else it is unknown, no fault codes, manual stopped or stopped for some other reason

#grep()
lagged = lagged %>%mutate(FaultCodeType =
  case_when(
  Description == "Gear Oil Temperature High"~"Critical",
  Description == "Gear Oil Pressure Too High/Low"~"Critical",
  Description == "Converter Tripped, Auto Start"~"Critical",
  Description == "Mainbreaker Cut Out"~"Critical",
  Description == "Gear Oil Pump/Blower Superheated"~"Critical",
  Description == "Ups Bypass Error"~"Critical",
  Description == "Ups-Failure"~"Critical"  ,
  Description == "Slip Ring Error"~"Critical",
  Description == "Osc. In Gen Speed, Cons. Lim"~"Critical",
  Description == "Ims-Gen Gearbearing Temp Too High"~"Critical",
  Description == "Ups-Failure"~"Critical",
  Description == "Hs-Gen Gearbearing Superheated "~"Critical",
  Description == "Grid Filter Current Overload"~"Critical",
  Description == "Gearoil Level Too Low"~"Critical",
  Description == "Rpm Sensor Error"~"Critical",
  Description == "Srsg Activated"~"Critical",
  Description == "Lms-Rot Gearbearing Temp Too High"~"Critical",
  Description == "Gear Oil Temperature Warning"~"Warning",
  Description == "Converter Trip, External"~"Warning",
  Description == "Converter Tripped, General"~"Warning",
  Description == "Main Bearing Temp Too High"~"Warning",
  Description == "Generator High Speed Waiting"~"Warning",
  Description == "Inv.(Tow) Cool Water Pres. Warning"~"Warning",
  Description == "Inv.(Tow) Cool Water Pres. Low"~"Warning",
  Description == "Tower Conv. Cooling Water Low"~"Warning",
  Description == "Hydraulic Filter Warning"~"Warning",
  Description == "Gear Oil Temp Sensor Warning"~"Warning",
  Description == "Main Bearing Temp Warning"~"Warning",
  Description == "Lmu Alarm Overspeed"~"Warning",
  Description == "Brake Pressure Too Low"~"Warning",
  Description == "Inverter Temperature High"~"Warning",
  Description == "Grdinv: 38 D1 Volt High"~"Warning",
  Description == "Grease Level Low, Gen Bearings"~"Warning",
  Description == "Grdinv: 38 D1 Volt High"~"Warning",
  Description == "Yaw Limit Sensor Activated"~"Warning",
  Description == "No Lubrication, Gen Bearings"~"Warning",
  Description == "Brake (Gen) Temperature Error"~"Warning",
  Description == "Dc Voltage Low"~"Warning",
  Description == "Grease Level Low, Hub"~"Warning",
  Description == "Geninv: 38 D1 Volt High"~"Warning",
  Description == "Gearoil Level Too Low"~"Warning",
  Description == "Geninv: 56 D3 Volt High"~"Warning",
  Description == "Inv. Cooling Water Temp Warning"~"Warning",
  Description == "Delta Module Temperature High"~"Warning",
  Description == "Gear Oil Temp Sensor Warning"~"Warning",
  Description == "Gear Bearing Hs-Gen Sensor Warning"~"Warning",
  Description == "Gear Bearing Hs-Rot Sensor Warning"~"Warning",
  Description == "Gear Bearing Ims-Gen Sensor Warning"~"Warning",
  Description == "Gear Bearing Ims-Rot Sensor Warning"~"Warning",
  Description == "Hs-Rot Gearbearing Temp Warning"~"Warning",
  Description == "Fuse Blown, Grid Filter"~"Warning",
  Description == "Hs-Gen Gearbearing Temp Warning"~"Warning",
  Description == "High Upper Voltage Exceeded"~"Warning",
  Description == "Low Lower Voltage Exceeded"~"Warning",
  Description == "UPS Battery Low, Warning"~"Warning",
  Description == "Ups Battery Low"~"Warning",
  Description == "Dc Fuse Blown"~"Warning",
  Description == "Gear Oil Temperature Low"~"Warning",
  Description == "Hydraulic Oil Too Cold"~"Warning",
  Description == "Blown Yaw Brake Fuse"~"Warning",
  Description == "Too Many Slip Ring Errors"~"Warning",
  Description == "No Lubrication, Yaw System"~"Warning",
  Description == "Lmu Sensor Error"~"Warning",
  Description == "Srsg Activated"~"Warning",
  .default ="Other"
))

lagged = lagged %>% mutate(BinaryFault = case_when(FaultCodeType == "Critical" ~ 1,
                                               .default = 0))
lagged = subset(lagged, select =-c(mean_windspeed, max_windspeed, min_windspeed, sd_windspeed))

# Output lagged dataset with FaultCodeType and BinaryFault.
write.csv(db2,paste(path_out,'final_data-v9-lagged.csv',sep = ''),row.names=FALSE)

lagged <- read.csv("Data/final_data-v8-lagged.csv", stringsAsFactors = TRUE)
# after reading in, must convert time date again.
lagged$round_date <- ymd_hms(lagged$round_date)
lagged$Date <- ymd(lagged$Date)

```

```{r output file, eval=FALSE}
#### ***Rmarkdown: Will not run when knitting unless you remove eval=FALSE ^


# Declare imputed data frame
ts_imputed = lagged
# remove windspeed

# list of turbines
turbine_list = unique(ts_imputed$location_id)
ts_imputed = arrange(ts_imputed, location_id, round_date)
# list of sensory columns names
column_list = colnames(ts_imputed)[c(7:38)]

# iterate through turbines then through each imputing column
for (i in 1:length(turbine_list)){
 print(paste0("imputing turbine: ", i))
 #subset because there are SO many missing values, so by doing it by turbine, you make it more accurate
 x = subset(lagged, location_id == turbine_list[i])
 for (j in column_list){
  print(paste0("imputing column: ", j))
  # use this time series imputing algorithm to fill in missing values
  imp = na_kalman(x[,j])
  # put data back into bhedata and we have a new dataframe that is all imputed!!!
  ts_imputed[ts_imputed$location_id == turbine_list[i],j] <- imp

 }

}

# Output Dataset imputed
write.csv(ts_imputed,paste(path_out,'final_data-v9-lagged-imputed.csv',sep = ''),row.names=FALSE)

```

## Matrix

```{r matrix, echo=TRUE,warning=FALSE,message=FALSE,error=FALSE,fig.keep='all'}
#Read in raw dataset
db <- read.csv("Data/final_data-v9-lagged.csv", stringsAsFactors = TRUE)

# after reading in, must convert time date again.
db$round_date <- ymd_hms(db$round_date)
db$Date <- ymd(db$Date)

numeric <- dplyr::select_if(db, is.numeric)
numeric <- subset(numeric, select =-c(FaultCode)) # These are technically a categorical variable
r <- cor(numeric, use="pairwise.complete.obs")
round(r,2)
ggcorrplot(r) + labs(title = "Correlation matrix")      


scatter_matrix = ggpairs(numeric, tittle="Scatterplot matrix")
# shouldn't run as it will freeze, instead used python with seaborn for a scatterplot matrix in the next code cluster
# ggplotly(scatter_matrix)

#Notes:
# We can see that the Gearbox oil temp and IMS temperature are directly related with correlation of .94.
# We can see that Active Power is also directly related to the Generator RPM at .94. Which seems right.
# We can see that Wind Speed is oddly inversely related to Hydraulic Pressure, Generator RPM, and active power. Probably due to a lack of wind data


```

```{python, scatterplotmatrix}
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

data = pd.read_csv("Data/final_data-v7-lagged.csv")
db2 = data.drop(columns =['FaultCode']) # these are Categorical 

# Seaborn scatterplot matrix
sns.pairplot(db2)
plt.show() #use to show in r mark down. Don't use when knitting to html


```


## Multivariate
```{r multivariate, figures-side, fig.show="hold", out.width="100%", fig.align="center", warning=FALSE}


g1 = ggplot(db %>%arrange(desc(FaultCodeType)),
       aes(x=Generator_RPM ,
           y=Active_Power,
           color = FaultCodeType,
           alpha = FaultCodeType))+
  ggtitle("Active Power Vs Generator RPM")+
  xlab("Genorator RPM")+
  ylab("Active Power")+
  scale_x_continuous(limits = c(500, 1400))+
  theme_bw()+
  scale_colour_manual(values = c("#DC267F", "#648FFF", "#FFB000"))+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), panel.background = element_blank())+
  geom_point()+ 
  scale_alpha_manual(values=c(1,0.05,1))

g2 = ggplot(db %>% filter(FaultCodeType != "Other")%>%arrange(desc(FaultCodeType)),
       aes(x=Generator_RPM,
           y=Active_Power,
           color = FaultCodeType,
           alpha = FaultCodeType))+
  ggtitle("Active Power Vs Generator RPM")+
  xlab("Genorator RPM")+
  ylab("Active Power")+
  scale_x_continuous(limits = c(500, 1400))+
  theme_bw()+
  scale_colour_manual(values = c("#DC267F", "#FFB000"))+
  scale_alpha_manual(values=c(1,0.05))+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), panel.background = element_blank())+
  geom_point()

  ggplot(fully_joined %>% filter(FaultCodeType != "Other")%>%arrange(desc(FaultCodeType)),
       aes(x=Timestamp,
           y=Bearing_Temp,))+
  ggtitle("Bearing Temp Time Series")+
  xlab("Date")+
  ylab("Temperature")+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), panel.background = element_blank())+
  geom_line()


grid.arrange(g1, g2,g3)


```

```{r, random_forest}
# reading in the lagged and imputed data set
forest_data <- read.csv("Data/final_data-v8-lagged-imputed.csv", stringsAsFactors = TRUE)
forest_data$BinaryFault <- as.factor(forest_data$BinaryFault)
forest_data$location_id <- as.factor(forest_data$location_id)
forest_data$round_date <- ymd_hms(forest_data$round_date)
forest_data$Date <- ymd(forest_data$Date)

#WIP

RNGkind(sample.kind = "default")
set.seed(231231)
train.idx <- sample(x = 1 : nrow(forest_data), size = .8*nrow(forest_data))
# make training data
train.df <- forest_data[train.idx, ]
#make testing data
test.df <- forest_data[-train.idx, ]


mtry <- c(1:8) # The maximum number of x variables are 8
keeps = data.frame(m = rep(NA, length(mtry)),
                   OOB_error_rate = rep(NA, length(mtry)))

for (idx in 1:length(mtry)){
  print(paste0("fitting m = ", mtry[idx]))
  
  tempForest  = randomForest(BinaryFault ~ Turbine + lagHSB + lagPressure + lagRPM + lagOil + lagIMS1 + lagIMS2 + lagPower,
                             data = train.df,
                             ntree = 1000,
                             mtry = mtry[idx])
  keeps[idx, "m"] = mtry[idx]
  keeps[idx, "OOB_error_rate"] = mean(predict(tempForest) != train.df$BinaryFault)
}

keeps
#plot
ggplot(data = keeps)+
  geom_line(aes(x = m, y = OOB_error_rate))+
  scale_x_continuous(breaks = c(1:8))+
  labs(x = "m (mtry): # of x variables sampled",
       y = "OOB Error rate")

# The smallest oob error with the Fault Code event is m = 4 or 6. 
finalForest <- randomForest(BinaryFault ~ lagHSB + lagPressure + lagRPM + lagOil + lagIMS1 + lagIMS2 + lagPower, # dangers here
             data = train.df,
             ntree = 1000, # b
             mtry = 4,
             importance = TRUE)
finalForest

pi_hat = predict(finalForest, test.df, type="prob")[,1]
#pit_hat is now a vector of predicted probabilities (of 1, critical fault codes)

rocCurve = roc(response = test.df$BinaryFault,
               predictor = pi_hat,
               levels=c(0,1))
plot(rocCurve, print.thres = TRUE, print.auc=TRUE)

pi_star = coords(rocCurve, "best", ret = "threshold")$threshold[1]
test.df$forest_pred = as.factor(ifelse(pi_hat>pi_star,1,0))

varImpPlot(finalForest, type = 1)
```
