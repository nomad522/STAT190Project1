---
title: "Project 1"
author: "Chris Cavan, Marshall Ndhlovu, Noah Maddio, Nathan Gottwals"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Processing

```{r Libraries, warning=FALSE,message=FALSE,error=FALSE, results='hide'}
rm(list = ls())
# libraries 
library(tidyverse)
library(lubridate)
library(dplyr)
library(ggcorrplot)
library(gridExtra)
library(tidyr)
library(ggplot2)
library(RColorBrewer)
library(reticulate)
library(fuzzywuzzyR)
library(plotly)
library(GGally)


# In reticulate's python environment install (from the r terminal):
# numpy
# polyfuzz
# seaborn
# pandas
# matplotlib

# python modules 
DIFFLIB <- reticulate::import("difflib")
POLYFUZZ <- reticulate::import("polyfuzz")


```
All r code and rmarkdown will be in the root directory with and all sensory data are to be in the directory Data/ and extracted into their respective sub directories as stated:\

**Work order**

+ Data/work order scrubbed.csv
  
**Active Power**

+ Data/Active Power
  
**Gearbox HS Bearing Temperature**
  
+ Data/Gearbox Bearing Temperature
  
**Gearbox IMS Bearing**
  
+ Data/Gearbox IMS Bearing
  
**Gearbox Oil Temperature**

+ Gearbox Oil Temperature
  
**Generator RPM**

+ Data/Gearbox RPM
  
**Hydraulic Pressure**

+ Data/Hydraulic Pressure
  
**Windspeed**

+ Data/Windspeed

#Reading in the data and cleaning
The data for the supplied sensor metrics are read in and the dates and time are converted to a usable date format. The data of the metrics are
then aggregated by the average in 15 minute intervals. The data frames are then joined by the Turbine and with the date and time of the averaged metric.


```{r data_processing, eval=FALSE}
#### ***Rmarkdown: Will not run when kniting unless you remove eval=FALSE ^


#####workorder------------
wo = read.csv("Data/work order scrubbed.csv")
# work order exploration and data cleaning
# cause_code all null
#table(wo$cause_code)
# start date is character
#convert start and finish columns to date objects
wo$wo_start_date = ymd_hms(wo$wo_start_date)
# end date is also character
#convert start and finish columns to date objects
wo$wo_finish_date = ymd_hms(wo$wo_finish_date)
#table(wo$cause_code)

# This first converts the string "null" into a NA value. Then by grouping of OrderNo, fills in NA's with existing values of component_type, within a OrderNo if they exist. Then distinct() is ran to keep only unique rows. This allows us to keep unique work order numbers with component types when it is available. 
workorder = wo %>% 
    mutate(component_type = case_when(component_type == "null" ~ NA_character_,
                               TRUE ~ component_type)) %>% 
    group_by(OrderNo) %>% 
    fill(component_type, .direction = 'up') %>% 
    fill(component_type, .direction = 'down') %>% distinct(OrderNo, .keep_all = TRUE)
# compared to this which just keeps distinct OrderNo regardless of other variables, causing us to lose most of the component_type 
# test = distinct(wo, OrderNo, .keep_all = TRUE)

str(workorder)

#### fault code---------------- 
fault_files = list.files("Data/Fault Codes", pattern="*.csv")
fault_list = list()
for (i in 1:length(fault_files)) {
  if (file.size(paste0("Data/Fault Codes/", fault_files[i])) >1){
    fault_list = c(fault_list, fault_files[i])
  }
}
fault = read.csv(paste0("Data/Fault Codes/", fault_list[1]), header = FALSE)
for (i in 2:length(fault_list)){
  new = read.csv(paste0("Data/Fault Codes/", fault_list[i]), header = FALSE)
  fault = rbind(fault, new)
}
#convert Datetime from char to date
fault$V2 <- ymd_hms(fault$V2)
#renaming column headers
names(fault) <- c("location_id", "DateTime", "Date", "FaultCode", "StatusCode", "Description", "Type")
fault <- fault %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 15 minute intervals
fault$round_date <- lubridate::round_date(fault$DateTime, "15 minutes")




#### Gearbox HS Bearing Temperature---------------- 
bearing_files = list.files("Data/Gearbox Bearing Temperature", pattern="*.csv")
bearing_list = list()
for (i in 1:length(bearing_files)) {
  if (file.size(paste0("Data/Gearbox Bearing Temperature/", bearing_files[i])) >1){
    bearing_list = c(bearing_list, bearing_files[i])
  }
}
bearing = read.csv(paste0("Data/Gearbox Bearing Temperature/", bearing_list[1]), header = FALSE)
for (i in 2:length(bearing_list)){
  new = read.csv(paste0("Data/Gearbox Bearing Temperature/", bearing_list[i]), header = FALSE)
  bearing = rbind(bearing, new)
}
#convert Datetime from char to date
bearing$V2 <- ymd_hms(bearing$V2)
#renaming column headers
names(bearing) <- c("location_id", "DateTime", "Date", "Temperature", "Bearing DE")
# Sorting data by turbine, then the DateTime. Then deleting rows with duplicate start times by turbine
bearing <- bearing %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 15 minute intervals
bearing$round_date <- lubridate::round_date(bearing$DateTime, "15 minutes")
#adding mean of the 15 minute intervals and dropping columns
bearing <- bearing %>% group_by(location_id, round_date) %>% summarise(mean_temp = mean(Temperature), .groups = 'drop') %>% as.data.frame()



#### Gearbox IMS Bearing Temperature---------------- 
ims_files = list.files("Data/Gearbox IMS Bearing", pattern="*.csv")
ims_list = list()
for (i in 1:length(ims_files)) {
  if (file.size(paste0("Data/Gearbox IMS Bearing/", ims_files[i])) >1){
    ims_list = c(ims_list, ims_files[i])
  }
}
ims = read.csv(paste0("Data/Gearbox IMS Bearing/", ims_list[1]), header = FALSE)
for (i in 2:length(ims_list)){
  new = read.csv(paste0("Data/Gearbox IMS Bearing/", ims_list[i]), header = FALSE)
  ims = rbind(ims, new)
}
#convert Datetime from char to date
ims$V2 <- ymd_hms(ims$V2)
#renaming column headers
names(ims) <- c("location_id", "DateTime", "Date", "Temperature", "ims")
# Sorting data by turbine, then the DateTime. Then deleting rows with duplicate start times by turbine
ims <- ims %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 15 minute intervals
ims$round_date <- lubridate::round_date(ims$DateTime, "15 minutes")
#adding mean ims bearing temp of the 15 minute intervals and dropping columns
ims <- ims %>% group_by(location_id, round_date) %>% summarise(mean_ims = mean(Temperature), .groups = 'drop') %>% as.data.frame()



#### Gearbox Oil Temperature---------------- 
oil_files = list.files("Data/Gearbox Oil Temperature", pattern="*.csv")
oil_list = list()
for (i in 1:length(oil_files)) {
  if (file.size(paste0("Data/Gearbox Oil Temperature/", oil_files[i])) >1){
    oil_list = c(oil_list, oil_files[i])
  }
}
oil = read.csv(paste0("Data/Gearbox Oil Temperature/", oil_list[1]), header = FALSE)
for (i in 2:length(oil_list)){
  new = read.csv(paste0("Data/Gearbox Oil Temperature/", oil_list[i]), header = FALSE)
  oil = rbind(oil, new)
}
#convert Datetime from char to date
oil$V2 <- ymd_hms(oil$V2)
#renaming column headers
names(oil) <- c("location_id", "DateTime", "Date", "Temperature", "oil")
# Sorting data by turbine, then the DateTime. Then deleting rows with duplicate start times by turbine
oil <- oil %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 15 minute intervals
oil$round_date <- lubridate::round_date(oil$DateTime, "15 minutes")
#adding mean oil temp of the 15 minute intervals and dropping columns
oil <- oil %>% group_by(location_id, round_date) %>% summarise(mean_oil = mean(Temperature), .groups = 'drop') %>% as.data.frame()



#### Generator RPM---------------- 
rpm_files = list.files("Data/Generator RPM", pattern="*.csv")
rpm_list = list()
for (i in 1:length(rpm_files)) {
  if (file.size(paste0("Data/Generator RPM/", rpm_files[i])) >1){
    rpm_list = c(rpm_list, rpm_files[i])
  }
}
rpm = read.csv(paste0("Data/Generator RPM/", rpm_list[1]), header = FALSE)
for (i in 2:length(rpm_list)){
  new = read.csv(paste0("Data/Generator RPM/", rpm_list[i]), header = FALSE)
  rpm = rbind(rpm, new)
}
#convert Datetime from char to date
rpm$V2 <- ymd_hms(rpm$V2)
#renaming column headers
names(rpm) <- c("location_id", "DateTime", "Date", "RPM", "Generator rpm")
# Sorting data by turbine, then the DateTime. Then deleting rows with duplicate start times by turbine
rpm <- rpm %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 15 minute intervals
rpm$round_date <- lubridate::round_date(rpm$DateTime, "15 minutes")
#adding mean rpm of the 15 minute intervals and dropping columns
rpm <- rpm %>% group_by(location_id, round_date) %>% summarise(mean_rpm = mean(RPM), .groups = 'drop') %>% as.data.frame()



#### Hydraulic Pressure---------------- 
hydraulic_files = list.files("Data/Hydraulic Pressure", pattern="*.csv")
hydraulic_list = list()
for (i in 1:length(rpm_files)) {
  if (file.size(paste0("Data/Hydraulic Pressure/", hydraulic_files[i])) >1){
    hydraulic_list = c(hydraulic_list, hydraulic_files[i])
  }
}
hydraulic = read.csv(paste0("Data/Hydraulic Pressure/", hydraulic_list[1]), header = FALSE)
for (i in 2:length(hydraulic_list)){
  new = read.csv(paste0("Data/Hydraulic Pressure/", hydraulic_list[i]), header = FALSE)
  hydraulic = rbind(hydraulic, new)
}
#convert Datetime from char to date
hydraulic$V2 <- ymd_hms(hydraulic$V2)
#renaming column headers
names(hydraulic) <- c("location_id", "DateTime", "Date", "Pressure", "Hydraulic Pressure")
# Sorting data by turbine, then the DateTime. Then deleting rows with duplicate start times by turbine
hydraulic <- hydraulic %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 15 minute intervals
hydraulic$round_date <- lubridate::round_date(hydraulic$DateTime, "15 minutes")
#adding hydrolic pressure to 15 minute intervals and dropping columns
hydraulic <- hydraulic %>% group_by(location_id, round_date) %>% summarise(mean_pressure = mean(Pressure), .groups = 'drop') %>% as.data.frame()



#### active power-------------- 
active_files = list.files("Data/Active Power", pattern="*.csv")
active_list = list()
for (i in 1:length(active_files)) {
  if (file.size(paste0("Data/Active Power/", active_files[i])) >1){
    active_list = c(active_list, active_files[i])
  }
}
active = read.csv(paste0("Data/Active Power/", active_list[1]), header = FALSE)
for (i in 2:length(active_list)){
  new = read.csv(paste0("Data/Active Power/", active_list[i]), header = FALSE)
  active = rbind(active, new)
}
#convert Datetime from char to date
active$V2 <- ymd_hms(active$V2)
#renaming column headers
names(active) <- c("location_id", "DateTime", "Date", "power", "Active power")
# sorting data by turbine, then the DateTime.
active <- active %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 15 minute intervals
active$round_date <- lubridate::round_date(active$DateTime, "15 minutes")
#adding mean power of the 15 minute intervals and dropping columns
active <-active %>% group_by(location_id, round_date) %>% summarise(mean_power = mean(power), .groups = 'drop') %>% as.data.frame()



#### Ambient Temperature-------------- Needs work*****
ambient_files = list.files("Data/ambient_temperature", pattern="*.csv")
ambient_list = list()
for (i in 1:length(ambient_files)) {
  if (file.size(paste0("Data/ambient_temperature/", ambient_files[i])) >1){
    ambient_list = c(ambient_list, ambient_files[i])
  }
}
ambient = read.csv(paste0("Data/ambient_temperature/", ambient_list[1]), header = FALSE)
for (i in 2:length(ambient_list)){
  new = read.csv(paste0("Data/ambient_temperature/", ambient_list[i]), header = FALSE)
  ambient = rbind(ambient, new)
}
#convert Datetime from char to date
ambient$V2 <- ymd_hms(ambient$V2)
#renaming column headers
names(ambient) <- c("location_id", "DateTime", "Date", "ambient_temp", "Ambient Temperature")
# sorting data by turbine, then the DateTime.
ambient <- ambient %>% 
  arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 15 minute intervals
ambient$round_date <- lubridate::round_date(ambient$DateTime, "15 minutes")
#adding mean power of the 15 minute intervals and dropping columns
ambient <-ambient %>% group_by(location_id, round_date) %>% summarise(mean_ambient = mean(ambient_temp), .groups = 'drop') %>% as.data.frame

#### Wind Speed-------------- 
wind_files = list.files("Data/Windspeed", pattern="*.csv")
wind_list = list()
for (i in 1:length(wind_files)) {
  if (file.size(paste0("Data/Windspeed/", wind_files[i])) >1){
    wind_list = c(wind_list, wind_files[i])
  }
}
wind = read.csv(paste0("Data/Windspeed/", wind_list[1]), header = FALSE)
for (i in 2:length(wind_list)){
  new = read.csv(paste0("Data/Windspeed/", wind_list[i]), header = FALSE)
  wind = rbind(wind, new)
}
#convert Datetime from char to date
wind$V2 <- ymd_hms(wind$V2)
#renaming column headers
names(wind) <- c("location_id", "DateTime", "Date", "windspeed", "Wind Speed")
# sorting data by turbine, then the DateTime.
wind <- wind %>% arrange(location_id, DateTime) %>% distinct()
#Adding a variable round_date to round times to nearest 15 minute intervals
wind$round_date <- lubridate::round_date(wind$DateTime, "15 minutes")
#adding mean power of the 15 minute intervals and dropping columns
wind <-wind %>% group_by(location_id, round_date) %>% summarise(mean_windspeed = mean(windspeed), .groups = 'drop') %>% as.data.frame()



####Joining datasets------
fully_joined <- full_join(fault, bearing, by=c('location_id', 'round_date')) %>%
  full_join(., wind, c('location_id', 'round_date')) %>%
  full_join(., hydraulic, c('location_id', 'round_date')) %>%
  full_join(., rpm, c('location_id', 'round_date')) %>%
  full_join(., oil, c('location_id', 'round_date')) %>%
  full_join(., ims, c('location_id', 'round_date')) %>%
  full_join(., active, c('location_id', 'round_date'))%>%
  full_join(., ambient, by=c('location_id', 'round_date'))

# Removing unused columns/duplicates
fully_joined <- subset(fully_joined, select = -c(DateTime, Date, StatusCode, Type, Date))

# Renaming columns
names(fully_joined) <- c("Turbine", "FaultCode","Discription", "Timestamp", "Bearing_Temp", "Windspeed", "Hydraulic_Pressure", "Generator_RPM", "Oil_Temp", "Gearbox_IMS", "Active_Power", "Ambient_Temp")



```

```{r fuzzy join work order, eval=FALSE}
#### ***Rmarkdown: Will not run when kniting unless you remove eval=FALSE ^

# fuzzy join workorder and fully_joined

unique(workorder$location_id)
workorder %>% ungroup()%>% summarise(min = min(wo_start_date),
                        max = max(wo_start_date))
# because we can see that we only have work orders from 2020-06-01 to 2022-01-31, we will create temporary subset for our sensory dataset to the newest, most recent of work order date so we maybe fuzzy match more closely for work orders to sensory data we have at that actual time or before it. New sensory data surely could not be predictive of prior work orders right?

joined_subset <- fully_joined[fully_joined$Timestamp < "2022-01-31",]


# Defining the two vectors we will be joining from a match. 
# from the work order info column we will find the most closely related fault code description
to_vec <- unique(joined_subset$Discription)
from_vec <- unique(workorder$Order_Info)
# removing the first 6 characters in hopes of better fuzzy matching
from_vec2 <- substr(from_vec, 6,nchar(from_vec))

get_best_matches <- function(from_vec2,to_vec) {
  
  get_best_matches <- function(from_string, to_vec){
    return(DIFFLIB$get_close_matches(from_string,to_vec, 1L, cutoff = 0))
  }
    unlist(lapply(from_vec2, function(from_vec2) get_best_matches(from_vec2, to_vec)))
  }
difflib_matches <- get_best_matches(from_vec2, to_vec)

get_score <- function(string1, string2) {
  return(SequenceMatcher$new(from_vec2[1],difflib_matches[1])$ratio())
}

get_score <- Vectorize(get_score)

difflib_scores <- get_score(from_vec2, difflib_matches)

fuzzy_list <- data.frame(from_vec, difflib_matches)
names(fuzzy_list) <- c("Order_Info", "Discription")

# joining the fuzzy match with work orders, so then workorder cam be joined to the sensory data by Discription, location_id, and approximate time. 
workorder <- full_join(workorder, fuzzy_list, by=c('Order_Info'))
#removing columns that are not useful. is_failure is always true because it's a work order and cause code is all null.
workorder <- subset(workorder, select = -c(is_failure, cause_code))

# convert dates from numeric to date format
workorder$wo_start_date <- ymd(workorder$wo_start_date)

# Removing the hms part from Timestamp and signing it to a variable Data to use as composite key for joining to the workorder.
fully_joined$Date = format(fully_joined$Timestamp, "%Y-%m-%d")
fully_joined$Date <- ymd(fully_joined$Date)


# full joining fully_joined and work order. joining by Turbine, Description(from fault code) and Date (not hms)
# Note: wo_start_date becomes Date. 
fully_joined = full_join(fully_joined, workorder, by = c("Turbine" = "location_id",
                                                            "Discription" = "Discription", 
                                                            "Date" = "wo_start_date"))


# looking at a subset of the join of the fully_joined and workorder frames for observations that have workorders (OrderNo)
# Seems right. The number of workorders after deleting duplicates was 139. merging with the sensory data by the 24 day period
# results in 172 obs as there can be multiple faultcodes and multiple time intervals when a WO is made. Unfortunately there is 
# not many sensory data for when a workorder is made.
test = fully_joined_wo[complete.cases(fully_joined_wo[,16]),]



```

```{r fault code discriptions, eval=FALSE}
#### ***Rmarkdown: Will not run when kniting unless you remove eval=FALSE ^

unique(fully_joined$Discription)
# If the Turbine stops and needs work, it's critical
# If the fault code is just a warning its a warning... something is wrong but still running
# else it is unknown, manual stopped or stopped for some other reason
# Due to the for loop, this takes a long time to run...
fully_joined$FaultCodeType = "Code Type"
suppressWarnings(
for (i in 1:nrow(fully_joined)){
  if (is.na(fully_joined$Discription[i])){fully_joined$FaultCodeType[i] = "Other"}
  else if (fully_joined$Discription[i] == "Gear Oil Temperature High"||
      fully_joined$Discription[i] == "Gear Oil Pressure Too High/Low"||
      fully_joined$Discription[i] == "Converter Tripped, Auto Start" ||
      fully_joined$Discription[i] == "Mainbreaker Cut Out"||
      fully_joined$Discription[i] == "Gear Oil Pump/Blower Superheated"||
      fully_joined$Discription[i] == "Ups Bypass Error"||
      fully_joined$Discription[i] == "Ups-Failure"||  
      fully_joined$Discription[i] == "Slip Ring Error"||
      fully_joined$Discription[i] == "Osc. In Gen Speed, Cons. Lim"||
      fully_joined$Discription[i] == "Ims-Gen Gearbearing Temp Too High"||
      fully_joined$Discription[i] == "Ups-Failure"||
      fully_joined$Discription[i] == "Hs-Gen Gearbearing Superheated"||
      fully_joined$Discription[i] == "Grid Filter Current Overload"||
      fully_joined$Discription[i] == "Gearoil Level Too Low"||
      fully_joined$Discription[i] == "Rpm Sensor Error"||
      fully_joined$Discription[i] == "Srsg Activated"||
      fully_joined$Discription[i] == "Lms-Rot Gearbearing Temp Too High"
      ){fully_joined$FaultCodeType[i] = "Critical"}
  else if (fully_joined$Discription[i] == "Gear Oil Temperature Warning"||
           fully_joined$Discription[i] == "Converter Trip, External"||
           fully_joined$Discription[i] == "Converter Tripped, General"||
           fully_joined$Discription[i] == "Main Bearing Temp Too High"||
           fully_joined$Discription[i] == "Generator High Speed Waiting"||
           fully_joined$Discription[i] == "Inv.(Tow) Cool Water Pres. Warning"||
           fully_joined$Discription[i] == "Inv.(Tow) Cool Water Pres. Low"||
           fully_joined$Discription[i] == "Tower Conv. Cooling Water Low"||
           fully_joined$Discription[i] == "Hydraulic Filter Warning"||
           fully_joined$Discription[i] == "Gear Oil Temp Sensor Warning"||
           fully_joined$Discription[i] == "Main Bearing Temp Warning"||
           fully_joined$Discription[i] == "Lmu Alarm Overspeed"||
           fully_joined$Discription[i] == "Brake Pressure Too Low"||
           fully_joined$Discription[i] == "Inverter Temperature High"||
           fully_joined$Discription[i] == "Grdinv: 38 D1 Volt High"||
           fully_joined$Discription[i] == "Grease Level Low, Gen Bearings"||
           fully_joined$Discription[i] == "Grdinv: 38 D1 Volt High"||
           fully_joined$Discription[i] == "Yaw Limit Sensor Activated"||
           fully_joined$Discription[i] == "No Lubrication, Gen Bearings"||
           fully_joined$Discription[i] == "Brake (Gen) Temperature Error"||
           fully_joined$Discription[i] == "Dc Voltage Low"||
           fully_joined$Discription[i] == "Grease Level Low, Hub"||
           fully_joined$Discription[i] == "Geninv: 38 D1 Volt High"||
           fully_joined$Discription[i] == "Gearoil Level Too Low"||
           fully_joined$Discription[i] == "Geninv: 56 D3 Volt High"||
           fully_joined$Discription[i] == "Inv. Cooling Water Temp Warning"||
           fully_joined$Discription[i] == "Delta Module Temperature High"||
           fully_joined$Discription[i] == "Gear Oil Temp Sensor Warning"||
           fully_joined$Discription[i] == "Gear Bearing Hs-Gen Sensor Warning"||
           fully_joined$Discription[i] == "Gear Bearing Hs-Rot Sensor Warning"||
           fully_joined$Discription[i] == "Gear Bearing Ims-Gen Sensor Warning"||
           fully_joined$Discription[i] == "Gear Bearing Ims-Rot Sensor Warning"||
           fully_joined$Discription[i] == "Hs-Rot Gearbearing Temp Warning"||
           fully_joined$Discription[i] == "Fuse Blown, Grid Filter"||
           fully_joined$Discription[i] == "Hs-Gen Gearbearing Temp Warning"||
           fully_joined$Discription[i] == "High Upper Voltage Exceeded"||
           fully_joined$Discription[i] == "Low Lower Voltage Exceeded"||
           fully_joined$Discription[i] == "UPS Battery Low, Warning"||
           fully_joined$Discription[i] == "Ups Battery Low"||
           fully_joined$Discription[i] == "Dc Fuse Blown"||
           fully_joined$Discription[i] == "Gear Oil Temperature Low"||
           fully_joined$Discription[i] == "Hydraulic Oil Too Cold"||
           fully_joined$Discription[i] == "Blown Yaw Brake Fuse"||
           fully_joined$Discription[i] == "Too Many Slip Ring Errors"||
           fully_joined$Discription[i] == "No Lubrication, Yaw System"||
           fully_joined$Discription[i] == "Lmu Sensor Error"||
           fully_joined$Discription[i] == "Srsg Activated"
  ){fully_joined$FaultCodeType[i] = "Warining"}
  else {fully_joined$FaultCodeType[i] = "Other"}
})

unique(fully_joined$FaultCodeType)

#Keeping only unique rows, for each time period and turbine there can be multiple fault codes, but exactly the same sensory data.
fully_joined <- fully_joined[!duplicated(fully_joined[,1:12]),]


```

```{r output file, eval=FALSE}
#### ***Rmarkdown: Will not run when kniting unless you remove eval=FALSE ^

# Output Dataset not imputed
path_out = 'Data//'
write.csv(fully_joined,paste(path_out,'final_data-v4.csv',sep = ''),row.names=FALSE)

#Impute Dataset
imputed_dataset = fully_joined_wo
#Replace all NA values in numeric columns with average column value.
imputed_dataset$Bearing_Temp[is.na(imputed_dataset$Bearing_Temp)] <- mean(imputed_dataset$Bearing_Temp,na.rm=TRUE)
imputed_dataset$Windspeed[is.na(imputed_dataset$Windspeed)] <- mean(imputed_dataset$Windspeed,na.rm=TRUE)
imputed_dataset$Hydraulic_Pressure[is.na(imputed_dataset$Hydraulic_Pressure)] <- mean(imputed_dataset$Hydraulic_Pressure,na.rm=TRUE)
imputed_dataset$Generator_RPM[is.na(imputed_dataset$Generator_RPM)] <- mean(imputed_dataset$Generator_RPM,na.rm=TRUE)
imputed_dataset$Oil_Temp[is.na(imputed_dataset$Oil_Temp)] <- mean(imputed_dataset$Oil_Temp,na.rm=TRUE)
imputed_dataset$Gearbox_IMS[is.na(imputed_dataset$Gearbox_IMS)] <- mean(imputed_dataset$Gearbox_IMS,na.rm=TRUE)
imputed_dataset$Active_Power[is.na(imputed_dataset$Active_Power)] <- mean(imputed_dataset$Active_Power,na.rm=TRUE)
imputed_dataset$Ambient_Temp[is.na(imputed_dataset$Ambient_Temp)] <- mean(imputed_dataset$Ambient_Temp,na.rm=TRUE)

# binary variable FaultOccurred. If a fault code is present in the time interval, Yes, if not,No.
imputed_dataset$FaultOccurred <-with(imputed_dataset, ifelse(is.na(db$FaultCode),"Yes","No"))
as.factor(imputed_dataset$FaultOccurred)

# Output Dataset imputed
write.csv(imputed_dataset,paste(path_out,'imputed_final_data.csv',sep = ''),row.names=FALSE)

```

## Matrix

```{r matrix, echo=TRUE,warning=FALSE,message=FALSE,error=FALSE, results='hide',fig.keep='all'}
#Read in raw dataset
db <- read.csv("Data/final_data-v4.csv")

# after reading in, must convert time date again.
db$Timestamp <- ymd_hms(db$Timestamp)
db$Date <- ymd(db$Date)
db$wo_finish_date <- ymd_hms(db$wo_finish_date)

# There are only 200 completed sensor metrics for the data set.
db2 = db[complete.cases(db[,5:12]),]

numeric <- dplyr::select_if(db, is.numeric)
numeric <- subset(numeric, select =-c(FaultCode, OrderNo)) # These are technically a categorical variable
r <- cor(numeric, use="pairwise.complete.obs")
round(r,2)
ggcorrplot(r) + labs(title = "Correlation matrix")


scatter_matrix = ggpairs(numeric, tittle="Scatterplot matrix")
# crash monster
# ggplotly(scatter_matrix)

#Notes:
# We can see that the Gearbox oil temp and IMS temperature are directly related with correlation of .92.
# We can see that Active Power is also directly related to the Generator RPM at .94. Which seems right.
# We can see that Wind Speed is oddly inversely related to Hydraulic Pressure, Generator RPM, and active power



```

```{python, scatterplotmatrix}
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

data = pd.read_csv("Data/final_data-v4.csv")
d2 = data.drop(columns =['FaultCode', 'OrderNo']) # these are Categorical 

# Seaborn scatterplot matrix
sns.pairplot(d2)

```

## Multivariate
```{r multivariate, figures-side, fig.show="hold", out.width="100%", fig.align="center", warning=FALSE}


g1 = ggplot(db %>%arrange(desc(FaultCodeType)),
       aes(x=Generator_RPM ,
           y=Active_Power,
           color = FaultCodeType,
           alpha = FaultCodeType))+
  ggtitle("Active Power Vs Generator RPM")+
  xlab("Genorator RPM")+
  ylab("Active Power")+
  scale_x_continuous(limits = c(500, 1400))+
  theme_bw()+
  scale_colour_manual(values = c("#DC267F", "#648FFF", "#FFB000"))+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), panel.background = element_blank())+
  geom_point()+ 
  scale_alpha_manual(values=c(1,0.05,1))

g2 = ggplot(db %>% filter(FaultCodeType != "Other")%>%arrange(desc(FaultCodeType)),
       aes(x=Generator_RPM,
           y=Active_Power,
           color = FaultCodeType,
           alpha = FaultCodeType))+
  ggtitle("Active Power Vs Generator RPM")+
  xlab("Genorator RPM")+
  ylab("Active Power")+
  scale_x_continuous(limits = c(500, 1400))+
  theme_bw()+
  scale_colour_manual(values = c("#DC267F", "#FFB000"))+
  scale_alpha_manual(values=c(1,0.05))+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), panel.background = element_blank())+
  geom_point()

g3 = ggplot(db %>%arrange(desc(FaultCodeType)),
       aes(x=Timestamp,
           y=Active_Power,
           color = FaultCodeType,
           alpha = FaultCodeType))+
  ggtitle("Active Power")+
  xlab("Date")+
  ylab("Active Power")+
  scale_x_continuous(limits = c(500, 1400))+
  theme_bw()+
  scale_colour_manual(values = c("#DC267F", "#648FFF", "#FFB000"))+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), panel.background = element_blank())+
  geom_point()+ 
  scale_alpha_manual(values=c(1,0.05,1))



grid.arrange(g1, g2)



```

